{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Phoebe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Phoebe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Phoebe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Phoebe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, glob\n",
    "import csv\n",
    "from functools import reduce\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk import word_tokenize, pos_tag_sents, pos_tag\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from string import punctuation\n",
    "import os, glob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "stops = set(stopwords.words(\"english\")) \n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "from wordcloud import WordCloud\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Direct Harassment\", \"Hate Speech\",\"Sexual Harassment\",\"Trolling\", \"Others\", \"Toxic\"]\n",
    "col = [\"preprocessed_1\", \"Direct Harassment\", \"Hate Speech\",\"Sexual Harassment\",\"Trolling\", \"Others\", \"Toxic\"]\n",
    "src_folder = \"tfidf_scores_results_per_video/\"\n",
    "files = [\"td_foxnews_FULL.csv\", \"td_rae_FULL.csv\", \"td_terror_FULL.csv\", \"td_usanews.csv\", \"td_nogla0.csv\", \"td_pew0.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_folder = \"correlations_of_tfidf_scores_per_label/\"\n",
    "file_prefix = \"sprmn_\"\n",
    "for file in files:\n",
    "    df = pd.read_csv(src_folder + file)\n",
    "    df_corr = df.corr(method=\"spearman\")\n",
    "    df_corr.to_csv(dest_folder + file_prefix + file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Phoebe\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(src_folder + files[3])\n",
    "dd = df[df.columns.difference(labels)]\n",
    "features = dd.columns\n",
    "dd[labels] = df[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pvals = pd.DataFrame(columns=cols)\n",
    "pvals = {}\n",
    "spm = {}\n",
    "for label in labels:\n",
    "    p_values = {}\n",
    "    sp_coeff = {}\n",
    "    for f in features:\n",
    "        sp, pval = spearmanr(dd[label], dd[f])\n",
    "        p_values[f] = pval\n",
    "        sp_coeff[f] = pval\n",
    "        \n",
    "    pvals[label] = pvals\n",
    "    spm[label] = sp_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_vals(df):\n",
    "    features = df.columns.difference(labels)\n",
    "    pvals = {}\n",
    "    spm = {}\n",
    "    for label in labels:\n",
    "        p_values = {}\n",
    "        sp_coeff = {}\n",
    "        for f in features:\n",
    "            sp, pval = spearmanr(df[label], df[f])\n",
    "            p_values[f] = pval\n",
    "            sp_coeff[f] = sp\n",
    "        pvals[label] = p_values\n",
    "        spm[label] = sp_coeff\n",
    "        \n",
    "        x = pd.DataFrame.from_dict(pvals)\n",
    "        y = pd.DataFrame.from_dict(spm)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, y = get_corr_vals(pd.read_csv(src_folder + files[3]))\n",
    "\n",
    "dest_folder = \"correlations_of_tfidf_scores_per_label/\"\n",
    "file_prefix_1 = \"pval_\"\n",
    "file_prefix_2 = \"spr_\"\n",
    "for file in files:\n",
    "    df = pd.read_csv(src_folder + file)\n",
    "    p, s = get_corr_vals(df)\n",
    "    p.to_csv(dest_folder + file_prefix_1 + file)\n",
    "    s.to_csv(dest_folder + file_prefix_2 + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bin biden crime          0.070484\n",
       "pedophiles biden vote    0.070484\n",
       "hunter bidens            0.070484\n",
       "joe 47 yrs               0.070484\n",
       "pedophiles biden         0.070484\n",
       "Name: Toxic, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = x['Toxic'].sort_values( ascending=True)\n",
    "b[b>0].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
